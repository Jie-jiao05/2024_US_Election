---
title: "A Prediction of the 2024 U.S. Election Outcome "
subtitle: "A Bayesian Spline Regression Analysis of Kamala Harris's Winning"
author: 
  - Shanjie Jiao
  - Aman Rana
  - Kevin Shen
thanks: "Code and data are available at: [https://github.com/Jie-jiao05/2024_US_Election.git)."
date: today
date-format: long
abstract: "The 2024 U.S. Presidential Election, set against a backdrop of economic and political challenges, features Donald Trump and Kamala Harris as the main candidates. This study uses Bayesian spline regression on polling data from FiveThirtyEight to predict the election outcome, capturing dynamic voter trends over time. Our analysis suggests a likely win for Kamala Harris, however a possible surprise by Donald Trump. Given the U.S.’s global influence, this result could significantly impact international security, trade, geopolitics, and provide a clear insight of forthcoming policy directions."
format: pdf
toc: true
number-sections: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false

library(knitr)
library(tidyverse)
library(arrow)
library(modelsummary)
library(rstanarm)
library(splines)
raw_data <- read_csv(here::here('data/01-raw_data/raw_data.csv'))
analysis_data <- read_parquet(here::here('data/02-analysis_data/analysis_data.parquet'))
analysis_data$end_date <- as.Date(analysis_data$end_date, format = "%m/%d/%y")
raw_data$end_date <- as.Date(raw_data$end_date, format = "%m/%d/%y")
```


# Introduction

The United States, as the world’s largest economy and most influential country, will hold its presidential election on November 5, 2024. Despite facing domestic challenges such as inflation, low employment rates after the pandemic, and increasing political polarization due to conflicts between the Democratic and Republican parties, which have accelerated internal tensions.As of October 2024, former President Donald Trump has secured the Republican Party nomination. Meanwhile, President Joe Biden withdrew from the election on July 21, leading to the nomination of Kamala Harris as the Democratic candidate. These events have made the 2024 U.S. election increasingly complex and unpredictable, further intensifying uncertainty about the future.

The estimand of this study is the predicted outcome of the 2024 U.S. Presidential Election for either Donald Trump or Kamala Harris, based on aggregated polling averages. Our analysis employs Bayesian spline regression to effectively capture the dynamic changes in voting trends over time, allowing us to forecast the likely election result. By comparing the predicted probabilities for both candidates, we aim to identify the probable winner based on current trends in voter support.

Using Bayesian spline regression analysis on the dataset provided by FiveThirtyEight [@FiveThirtyEight], this study forecasts the outcome of the 2024 U.S. election, predicting a victory for Kamala Harris.

Due to the United States' hegemonic position and unparalleled global influence, the outcome of the U.S. election will serve as a guiding light for global developments over the next four years, significantly impacting international security, trade, cooperation, and geopolitics. This article aims to provide a clearer analytical framework for political scientists, the general public, journalists, corporate strategists, and anyone globally concerned with the U.S. election.

The remainder of this paper is structured as follows. In the Data Section we will discuss the data used in the modelling process and the result of the Bayesian Spline fit with its predictor variables and the response after transformation. In the Discussion we delve into the shortcomings of the study and areas for improvement will be described.Appendix is a A Deep Dive to a pollster will be conducted, and Appendix B we will given a idealized survey and methodology

# Data {#sec-data}

## Overview

We use R [@citeR] and Python [@citePython] to analyze a panel of poll data from Project FiveThirtyEight [@538]. It consists of voter support data from major pollsters in the US, with national and state-level polls. The data includes labels for pollster robustness as constructed by FiveThirtyEight. Polling date data is included, which gives us snapshots of the progressing state of the general election.

Our analysis is focused on determining whether Donald Trump or Kamala Harris will win the election. We drop all other candidates and parties on the belief that they are not likely to win given how close the race is between the two leading candidates.

For every observation in our data we have percentage of voter support, state, start and end dates of the poll, pollster quality, and party.

## Data Quality Variable: Numeric_Grade
```{r}
#| label: numeric_grade_dist
#| fig-cap: Distribution of Numeric Grades
#| warning: false
#| echo: false
ggplot(raw_data, aes(x = numeric_grade)) +
  geom_histogram(binwidth = 0.1, color = "black", fill = "lightblue") +
  labs(title = "Distribution of Numeric Grades", x = "Numeric Grade", y = "Frequency")
```

Numeric_Grade is a numeric rating given by FiveThirtyEight to indicate a pollsters quality or reliability. The rating is based on methodology, transparency and historical accuracy which is important for our analysis as we evaluate eahc poll observation. The raw data set has the following distribution with numeric grades (@numeric_grade_dist). We choose to drop all polls with numeric grades less than 3 to keep only the highest quality polls.

## Predictor Variable: State
```{r}
#| label: state_dist
#| fig-cap: Distribution of Observations by State
#| echo: false
analysis_data$state[is.na(analysis_data$state)] <- "National"
state_counts <- analysis_data %>%
  count(state) %>%
  mutate(percentage = n / sum(n) * 100)
ggplot(state_counts, aes(x = state, y = percentage)) +
  geom_bar(stat = "identity", color = "black", fill = "lightblue") +
  labs(title = "Distribution of Observations by State (Percentage)", x = "State", y = "Percentage") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
The state where the polling took place. This is important for state-level fixed effects, some regions show more supoprt to one party over another. Regarding the data itself, ee notice that over half of all observations are NA, in our analysis we take these to be national level polls. Since this is not explicit in the documentation [@538], this is an assumption which is a caveat in our outcome analysis. We notice in the figure (@state_dist) that not every state is represented, which limits us to the states we can make state-level predictions for.

## Predictor Variable: Party
The party variable identifies whether the observation is for the Democratic
or Republican party. What we are interested in is the most-likely presidential candidate
so we remove any data before Kamala Harris was announced on July 21 2024, which allows us to use party as a proxy for candidate.
```{r}
#| label: party_counts
#| fig-cap: Distribution of Observations by Party
#| echo: false
party_counts <- analysis_data %>%
  count(party)

# Display the table
kable(party_counts, caption = "Distribution of Observations by Party")
```
## Predictor Variable: end_date_num
End_date is the end date of the poll and represents the informational cut off date that
the results of a poll indicate. We include this as one of the variables in our regression
in order to capture time effects such as the momentum and changing support of a candidate over time. End_date_num is the number of days since the start of the period, it increases as we approach the election period. We include it to measure the time effects, we might expect Trump's roportion to increase as end_date_num increases as we have seen historically due to shy voters @cohn_2024.

Plotting a histogram of end dates, we see how polls become much more frequent over time as the election approaches. 

```{r}
#| label: end_date_history
#| fig-cap: Number of Polls over Time
#| echo: false
poll_counts <- raw_data %>%
  mutate(month = floor_date(end_date, "month")) %>%
  count(month)

# Plot the number of polls over time, by month using bars
ggplot(poll_counts, aes(x = month, y = n)) +
  geom_bar(stat = "identity", fill = "skyblue", color = "black") +
  labs(title = "Number of Polls over Time (Monthly)", x = "Month", y = "Frequency") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
## Predictor Variable: pollster
```{r}
#| label: pollster_counts
#| fig-cap: High-Grade Poll counts by Pollster
#| echo: false
pollster_counts <- analysis_data %>%
  count(pollster)

# Display the table
kable(pollster_counts, caption = "High-Grade Poll counts by Pollster" )
```
Pollsters are the agencies that do the polls, in our datasetwe find only a few pollsters
remain as seen below. We include pollsters in our regression to account for any pollster
effects, bias can come from the pollsters themselves, or the demographics they serve. While we
do not expect this effect to be strong since we limit ourselves to the highest grade of polls
we retain this vairbale for completeness. Additionaly we notice one of the remaining pollsters
'YouGov/Center for Working Class Politics' has very few observations and we drop this because it is not well represented in the regression. The polls are from a collaboration with YouGov and a different entity [@YG_CWC] and so we see it as distinct form a YouGov poll and do not merge the two.

##Outcome Variable: pct

Pct represents percentage of support, the percentage of respondents that support each party. This is our primary outcome of interest, and will be the target of our regression. To note is that for a particular poll the sum of our pct does not add up to 100. Since we drop 
other parties, they are not represented in our data and their omission causes the sum to not be 100.

```{r}
#| label: pct
#| echo: false
#| fig-cap: "Distribution of Percentage support shows us how each party's support is distributed around 46%, showcasing the close nature of the election"
# Create frequency table of pct values by party
freq_data <- analysis_data %>%
  filter(party %in% c("REP",  "DEM")) %>%
  mutate(pct_bin = cut(pct, breaks = seq(0, 100, by = 0.01))) %>%  # Bin pct into intervals of 5
  group_by(party, pct_bin) %>%
  summarise(freq = n(), .groups = 'drop')

# Generate the dodge plot for binned pct distribution by party with custom colors
ggplot(freq_data, aes(x = pct_bin, y = freq, fill = party)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  labs(title = "Distribution of Percentage Support by Party (Binned)",
       x = "Percentage Support (pct) Binned",
       y = "Frequency") +
  theme_minimal() +
  scale_fill_manual(values = c("REP" = "red", "DEM" = "blue")) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate x-axis labels for readability
```

# Model

Our model is designed to estimate temporal trends in party support as reflected in polling percentages for the Democratic and Republican parties. We employ a Bayesian framework to capture uncertainty and provide flexibility in trend estimation over time. Based on our understanding of state-level variances @538, and possible pollster bias, we include them as variables.

## Model Set-up

The response variable \( y_i\) represents the percentage voter support for a given poll \(i\). The explanatory variables:
- \(\text{end\_date\_num}_i\): the number of days since the earliest poll date for the given party,
- \( \text{pollster}_i \): the pollster conducting the poll, and
- \( \text{state}_i \): the U.S. state where the poll was conducted (or "National" if the poll was nationwide).

For each party, we fit a separate Bayesian model with spline smoothing on \( \text{end\_date\_num}\) to capture time trends, alongside fixed effects for both pollster and state. We implement the model in R using the `rstanarm` package [@citeR].

The model’s hierarchical structure and notation are as follows:

\[
\begin{align}
y_i | \mu_i, \sigma &\sim \text{Normal}(\mu_i, \sigma) \\
\mu_i &= \alpha + f(\text{end\_date\_num}_i) + \text{pollster}_i + \text{state}_i \\
\alpha &\sim \text{Normal}(50, 10) \\
f(\text{end\_date\_num}) &\sim \text{B-spline basis expansion} \\
\text{pollster}_i &\sim \text{Normal}(0, 5) \\
\text{state}_i &\sim \text{Normal}(0, 3) \\
\sigma &\sim \text{Exponential}(1)
\end{align}
\]

### Explanation of Components

- **Response variable \( y_i\)**: Observed polling voter support percentage for each poll \(i\). This represents the percentage of voter support.

- **Mean structure \(\mu_i \)**: Consists of four components:
  - **Intercept \( \alpha \)**: Represents the baseline average percentage across all polls.
  - **Spline component \( f(\text{end\_date\_num}_i) \)**: Captures temporal trends in polling percentages over time, modeled using a B-spline basis expansion. This allows the trend to adjust flexibly over time, fitting the non-linear trends typically observed in polling data.
  
  - **Pollster effect \( \text{pollster}_i \)**: A fixed effect to account for systematic differences across pollsters. Due to varying methodologies and sampling practices, some pollsters may produce consistently higher or lower estimates.
  
  - **State effect \( \text{state}_i \)**: A fixed effect accounting for differences across states. Given the diversity in political landscapes across U.S. states, this term allows for state-specific adjustments, capturing the influence of state-level variability on polling trends. For example, large or politically heterogeneous states may exhibit unique polling behaviors that could impact results.

### Priors
- **Intercept \(\alpha \sim \text{Normal}(50, 10) \)**: Centered around 50%, allowing flexibility given historical polling percentages range from 0% to 100%.
- **Pollster effect prior \( \text{Normal}(0, 5) \)**: This moderate prior accounts for typical systematic differences by pollster, usually less than 5% on average.
- **State effect prior \( \text{Normal}(0, 3) \)**: Reflects an expected range of moderate variation across states, accounting for demographic or political differences that may influence polling results.
- **Spline basis priors**: Each spline coefficient has a `Normal(0, 5)` prior, allowing moderate variation in temporal trends without overfitting.
- **Error term \(\sigma \sim \text{Exponential}(1) \)**: This prior allows positive values with most mass around lower standard deviations, yet still accommodates higher values in the presence of greater noise.

### Model Implementation
The model is implemented with `rstanarm` and `stan_glm`, @rstanarm with spline terms on \(\text{end\_date\_num}\) and fixed effects for both pollster and state. This structure enables us to capture time trends while also adjusting for pollster and state-level variability. The Bayesian framework in `rstanarm` allows us to derive credible intervals around predictions, aligning with our focus on uncertainty quantification.

### Diagnostics and Validation
Model diagnostics are crucial to ensure reliability and robustness:
- **Posterior Predictive Checks**: We use `pp_check` functions to visually compare observed and model-predicted polling percentages. These checks help assess whether the model captures the data patterns effectively. And gives us an interpretable belief system.
- **Convergence Diagnostics**: R-hat values close to 1 and trace plots are manually inspected to confirm the convergence of the Markov Chain Monte Carlo (MCMC) sampling.
- **Sensitivity Analysis**: We tested several values for the spline degrees of freedom (`df = 4` was chosen) to avoid overfitting.
- **Out-of-Sample Validation**: Future work will include a test-train split for validating predictions on unseen data, using metrics like Root Mean Square Error (RMSE) and Mean Absolute Error (MAE) to assess predictive performance.

### Alternative Models Considered
We considered the following alternatives:
1. **Non-Spline Linear Trend Model**: A simpler model assuming a linear trend in \( \text{end\_date\_num} \). However, this approach did not capture the observed non-linear trends over time.
2. **Pollster Only Model (without State Effects)**: A model without state effects was tested, but we felt that fundamentally state effects are important and should be included

The selected model—using a spline with both pollster and state fixed effects—was chosen for its ability to balance flexibility with robustness, capturing essential polling trends without excessive complexity.

### Assumptions and Limitations
This model assumes that polling trends over time follow a relatively smooth pattern and that pollster and state effects are additive and consistent over time. We note that interactions between states, their co movement with each other @538 are not included, and that this is 
a simplistic model.

# Results

Here we present the results of our analysis of the election cycle. First we look at a cross-sectional summary of the
landscape, state-wise polling averages of each party. Then we look at the prediction from our regression of the possible outcomes and evaluate whether the Democrats or Republicans have a higher voter support percentage as per our Bayesian model. We finally look at the posterior beliefs generated by our model and use them to make a conclusion on election outcomes.


@cross_summary_stats shows us the cross sectional stats for the polling data.
We determine that on average across all time, the Democrats under Harris have a marginal lead.
However, given that these polls have confidence intervals of 3% on average, this is well within a margin of error.

```{r}
#| label: cross_summary_stats
#| echo: false
#| warning: false
library(dplyr)
library(knitr)

summary_stats <- analysis_data %>%
  summarise(
    avg_pct_dem = round(mean(pct[party == "DEM"], na.rm = TRUE), 3),
    avg_pct_rep = round(mean(pct[party == "REP"], na.rm = TRUE), 3),
    min_pct_dem = round(min(pct[party == "DEM"], na.rm = TRUE), 3),
    max_pct_dem = round(max(pct[party == "DEM"], na.rm = TRUE), 3),
    min_pct_rep = round(min(pct[party == "REP"], na.rm = TRUE), 3),
    max_pct_rep = round(max(pct[party == "REP"], na.rm = TRUE), 3),
    poll_count = n(),
    min_date = min(end_date, na.rm = TRUE),
    max_date = max(end_date, na.rm = TRUE)
  )

# Display the table with improved formatting
summary_stats %>%
  kable(
    caption = "Summary Statistics of Polling Data",
    col.names = c(
      "Avg % DEM", "Avg % REP", "Min % DEM", "Max % DEM",
      "Min % REP", "Max % REP", "Poll Count", "Earliest Date", "Latest Date"
    ),
    format = "pipe"
  )

```

## National Polling Trends for Democratic and Republican Parties
First we observe the results from the 'National' state, which are the polls with no state label, that we assumed
to be national polls. Our Bayesian spline model allows us to examine trends and quantify the uncertainty.

```{r}
#| label: bayesian_outcome_stats
#| echo: false
#| warning: false
data <- read_parquet(here::here("data/02-analysis_data/analysis_data.parquet"))

# Separate data by party, handle missing states, and calculate num_dem and num_rep
dem_data <- data |>
  filter(party == "DEM") |>
  mutate(
    state = if_else(is.na(state), "National", state),
    end_date = mdy(end_date),
    num_dem = round((pct / 100) * sample_size, 0)
  )

rep_data <- data |>
  filter(party == "REP") |>
  mutate(
    state = if_else(is.na(state), "National", state),
    end_date = mdy(end_date),
    num_rep = round((pct / 100) * sample_size, 0)
  )

# Convert pollster and state to factors
dem_data <- dem_data |>
  mutate(
    pollster = factor(pollster),
    state = factor(state)
  )

rep_data <- rep_data |>
  mutate(
    pollster = factor(pollster),
    state = factor(state)
  )

# Convert end_date to number of days since the earliest poll
dem_data <- dem_data |>
  mutate(
    end_date_num = as.numeric(end_date - min(end_date))
  )

rep_data <- rep_data |>
  mutate(
    end_date_num = as.numeric(end_date - min(end_date))
  )

# Create new data for prediction, including state
new_data <- data.frame(
  end_date_num = seq(
    min(dem_data$end_date_num),
    max(dem_data$end_date_num),
    length.out = 100
  ),
  pollster = factor("YouGov", levels = levels(dem_data$pollster)),
  state = factor("National", levels = levels(dem_data$state))
)
rep_new_data <- data.frame(
  end_date_num = seq(
    min(rep_data$end_date_num),
    max(rep_data$end_date_num),
    length.out = 100
  ),
  pollster = factor("YouGov", levels = levels(rep_data$pollster)),
  state = factor("National", levels = levels(rep_data$state))
)

spline_model <- readRDS(here::here("models/democrat_model.rds"))
rep_spline_model<- readRDS(here::here("models/republican_model.rds"))

# Predict posterior draws
posterior_preds <- posterior_predict(spline_model, newdata = new_data)
rep_posterior_preds <- posterior_predict(rep_spline_model, newdata = rep_new_data)

# Summarize predictions
pred_summary <- new_data |>
  mutate(
    pred_mean = colMeans(posterior_preds),
    pred_lower = apply(posterior_preds, 2, quantile, probs = 0.025),
    pred_upper = apply(posterior_preds, 2, quantile, probs = 0.975)
  )

rep_pred_summary <- rep_new_data |>
  mutate(
    pred_mean = colMeans(rep_posterior_preds),
    pred_lower = apply(rep_posterior_preds, 2, quantile, probs = 0.025),
    pred_upper = apply(rep_posterior_preds, 2, quantile, probs = 0.975)
  )

# Rename columns to standardize
colnames(dem_data)[colnames(dem_data) == "num_dem"] <- "num"
colnames(rep_data)[colnames(rep_data) == "num_rep"] <- "num"

# Combine data and prediction summaries for final plot
combined_data <- rbind(dem_data, rep_data)
pred_summary$party <- "DEM"
rep_pred_summary$party <- "REP"
pred_summary_combined <- rbind(pred_summary, rep_pred_summary)

# Final combined plot with state effects
ggplot(combined_data, aes(x = end_date_num, y = pct, color = party)) +
  geom_point(aes(shape = pollster)) +
  geom_line(
    data = pred_summary_combined,
    aes(x = end_date_num, y = pred_mean, color = party),
    inherit.aes = FALSE
  ) +
  geom_ribbon(
    data = pred_summary_combined,
    aes(x = end_date_num, ymin = pred_lower, ymax = pred_upper, fill = party),
    alpha = 0.2,
    inherit.aes = FALSE
  ) +
  labs(
    x = "Days since earliest poll",
    y = "Percentage",
    title = "National Poll Percentage over Time with Spline Fit"
  ) +
  scale_color_manual(values = c("blue", "red")) +
  scale_fill_manual(values = c("blue", "red")) +
  theme_minimal()
```

### Bayesian Spline Model

- **Smoothed Prediction Line**: The Bayesian spline model generates the smoothed trend line (blue for Democrats and red for Republicans) on the plot. This line represents the posterior mean, the expected polling percentage over time after accounting for individual poll variability.
  
- **Uncertainty Interval**: The shaded area around each trend line represents the 95% credible interval derived from the Bayesian model’s posterior predictions. This interval provides a measure of uncertainty, highlighting where actual polling values are likely to fall based on the model’s posterior distribution.

### Key Observations

- **Trend for Democratic Party**: The smoothed trend line for the Democratic Party shows that support for the Democrats has been stable and above that of the Republicans.

- **Trend for Republican Party**: For the Republican Party, the trend line indicates more variability in their support, but a more increasing trend in the most recent past.

- **Comparative Insights**: By comparing the two we find that the Democrats are in the lead but not by a significant margin, and that the Republicans are showing some recent momentum. However, the credibility intervals are so large, they overlap. As such, there is no significant conclusion. Within the credibility intervals are scenarios where the Republicans lose with 42% and the Democrats win with 52%, as well as scenarios where the Republicans win with 51% and the Democrats lose with 42%.

## Posterior predictive check

In @combined_pp_check we implement a posterior predictive check. Our prior belief is a normal distribution around 50, and our posterior shows how much that has been updated by the data. 

We find that the democrat posterior forms a table with a fatter tail below 50, indicating that the uncertainty is more on the lower side, our confidence in the voter support estimate is not strongly concentrated around a single mean value, but decays to the left.

The inverse is true for the Republican posterior where the spike is lower, indicating a higher confidence in their possible voter support,
but a fatter right tail, indicating a higher surprise probability.

```{r} 
#| label: combined_pp_check
#| echo: false
#| warning: false
#| layout-ncol: 2
#| fig-cap: "Comparison of Posterior Predictive Checks: Democrats vs Republicans Models. The Democrat model shows a fat tail below 50, suggesting higher probability of downward surprises. The Republican model has a fatter right tail, indicating a higher probability of upward surprises."

# Democrats model
plot1 <- pp_check(spline_model) +
  theme_classic() +
  labs(
    title = "Democrats Model",
    subtitle = "Fatter tail below 50 suggests higher chance of downward surprises",
    x = "Predicted Outcome",
    y = "Density"
  ) +
  theme(legend.position = "bottom")

# Republicans model
plot2 <- pp_check(rep_spline_model) +
  theme_classic() +
  labs(
    title = "Republicans Model",
    x = "Predicted Outcome",
    y = "Density"
  ) +
  theme(legend.position = "bottom")

# Display plots side-by-side in R Markdown
plot1
plot2
```
A model summary for the Republican and Democrat fits can be found in the Appendix @sec-model-details.

# Discussion {#sec-dis}

## Discussion of Empirical Results {#sec-first-point}

Our results section allows us to make some inferences. First, we see that the Democrats are ahead, and we predict a win for Kamala Harris. However, the time series of the spline shows us that their support has been flat over time, whereas the Republican party has been showing some recent momentum which could contribute to a surprise. This is in-line with some of the literatue, with @cohn_2024 showing how Trump brings his strength later in the election cycle as voters are generally shy to show their support for him.

Our posterior checks show the variability in our uncertainty. Since we do not have normal posteriors, we can make nuanced inferences on the confidences of our prediction. The Democrats do have a higher projected voter support, but the distribution from which this came has a fatter tail on the left, and drops sharply above 49%. Which means the mean is high, but there is a substantial portion of the distribution that is in a lower voter support percentage. Additionally, if we look at the Republican posterior, it has a sharp spike near its mean, which means it is likely that they will get the losing voter support of 45%, but,
it has a fat tail that shows that there is an unlikely but possible outcome that they win with a surprise.

We can conclude, that the democrats are strongly favoured to win, but the Republicans do also have a stronger probability of an upward surprise, whereas the democrats have a stronger probabiltiy of a downward surprise.

## Limitations and Weaknesses

Our model, while providing valuable insights into voter support dynamics, has several important limitations:

- **Smoothness Assumption:** The spline regression framework assumes smooth changes in voter preferences over time, potentially missing abrupt shifts after major campaign events or breaking news.
- **Static Pollster Quality:** Pollster quality is treated as a static measure in our model, ignoring that polling methodology and accuracy may vary over the campaign period - pollsters could improve or become less reliable over time.
- **Limited Geographic-Temporal Interaction:** While our model includes state-level effects, it doesn't account for time-state interactions - patterns of changing support may vary across states in ways our current specification cannot capture.
- **National Poll Classification:** We assume that polls with a NaN state value are National level polls, but this is a spurious assumption. We could be introducing state biases to the outcomes.

Despite using only polls with numeric grades above a threshold, variations in pollster methodology and inherent biases in which demographics are sampled can introduce significant uncertainties. While a high numeric grade provides some quality assurance, it cannot guarantee that a pollster's methodology is free from systematic biases in terms of which population groups they reach and survey. This limitation becomes particularly apparent when considering differential voter turnout, as polls may not adequately capture certain demographic segments of the voting population, leading to coverage bias - a significant error that occurs when there is a mismatch between the sampling frame (the population being surveyed) and the actual target population of likely voters [@stantcheva2023run].

\newpage

\appendix

# Appendix 
## A: Emerson College Polling Methodology Analysis {#sec-Appendix-A}

### Overview
Emerson College Polling (ECP) is a nationally recognized, non-partisan polling organization [@emerson2024about]. ECP conducted a national survey from October 30 to November 2, 2024, targeting 1,000 likely voters in the 2024 U.S. presidential election. The poll measured voter preferences between candidates Kamala Harris and Donald Trump, indicating a tie at 49% each, with third party candidates and undecided voters at one percent each [@emerson2024november]. Appendix A examines the methodology used by ECP for this poll.

### Survey Population and Sampling
When conducting a poll, it is crucial to define the target population, sampling frame, and sample in order to provide a clear direction and objective [@whaley2024understanding].

The target population is the entire group about which we aim to understand and draw conclusions from [@tellingstories]. For this poll, the target population consists of likely voters in the 2024 U.S. presidential election. ECP determines likely voters through a combination of voter history, registration status, and self-reported demographic data [@emerson2024november].

Since it is oftentimes infeasible to gather data from the entire target population, sampling frames and samples are utilized. A sampling frame is the list of all units from which samples can be taken [@tellingstories]. In this poll, the sampling frame consists of voters available on Aristotle's database and the online panel provided by CINT [@emerson2024november]. Aristotle maintains comprehensive voter and consumer data [@aristotle2024data], while CINT operates as a global research marketplace connecting researchers to survey respondents [@cint2024]. The sample consists of 1,000 likely voters selected from this frame.

### Data Collection and Sampling Approach
ECP employs a mixed-mode sampling methodology for its polling [@emerson2024about]. When collecting data for its October 30 to November 2, 2024 U.S. Presidential Election poll, three primary methods were used [@emerson2024november]:

1. MMS-to-web text survey: Respondents receive text messages with custom graphics inviting them to take online Qualtrics survey. Selected randomly from Aristotle voter files.
2. Online panel surveys: CINT panel respondents screened for voter registration and demographics, then directed to survey with quality checks.
3. Interactive Voice Response (IVR): Automated calls to landlines where permitted. Respondents use touch-tone phones. Selected randomly from Aristotle voter files.

This mixed-mode approach offers several advantages, primarily reducing coverage bias by reaching different demographic groups within the target population. Coverage bias occurs when there is a discrepancy between the sampling frame and the target population [@stantcheva2023run]. By employing multiple methods, ECP minimizes this bias: MMS-to-web surveys typically capture younger voters, IVR targets older and rural voters who prefer landlines, and online panels engage tech-savvy individuals. A mixed-mode approach can also reduce fieldwork costs by maximizing the use of lower cost methods, and using higher cost methods when necessary [@wilkinson2020mixed]. However, this approach introduces measurement error as each method brings its own biases [@emerson2024about], potentially increasing the overall margin of error.

### Non-response Handling
In polling, non-response occurs when subjects either refuse to participate in a survey or skip specific questions, limiting the survey's representativeness beyond its respondents. To address this issue and ensure representativeness, ECP implements a weighting system based on multiple demographic variables:

- Gender
- Education
- Race
- Age
- Party registration
- Region

These weights are calculated based on 2024 likely voter modeling, adjusting for under- and over-represented groups in the sample [@emerson2024november].

### Questionnaire Design
The survey's questionnaire demonstrates both strengths and limitations. Its strengths include:

- Clear, unambiguous question formulation
- Efficient format
- Topical relevance focusing on vote preferences and key demographic splits

However, the questionnaire's limitations include:

- Limited exploration of underlying voter motivations
- Potential variation in response quality across different survey modes
- Basic preference capture without deeper attitudinal investigation
- All data collection was conducted in English, potentially limiting representation of non-English speaking voters.

The survey maintains a credibility interval of +/- 3 percentage points, with higher intervals for demographic subsets due to reduced sample sizes.

### Conclusion
Emerson College Polling's mixed-mode methodology effectively balances cost with demographic reach. While their weighting system helps ensure representativeness, the multi-mode approach presents trade-offs: reduced coverage bias through diverse voter outreach, but increased measurement error from combining different survey methods [@mora2011understanding]. These methodological considerations are crucial when interpreting the poll's results.


## B: Idealized Survey Methodology – $100K Budget {#sec-Appendix-B}

### Introduction
In this appendix, we outline an idealized survey methodology for forecasting U.S. presidential elections within a budget of up to $100,000. The proposed design aims to maximize accuracy and cost-efficiency by strategically selecting sample populations, targeting key demographic groups, and effectively aggregating results.

### Sampling Strategy
The ideal survey methodology employs a stratified random sampling approach, given the diversity of the American population as the target group. This method is designed to better analyze the varying effects of different races, age groups, genders, and education levels on voting trends by distributing the sample into multiple subgroups. By categorizing these key variables, this approach ensures more concise and clearer statistical results, which in turn facilitates in-depth analysis. The representative sample is listed below:

- **Sampling Frame**: For the information security, valid entitlement holders registered on the voter list and registered with the Census Bureau will receive the survey. 
- **Sampling Method**: Stratified random sampling will be implemented, ensuring better analyze the differential impact of different key factors, including races, ages, genders, and levels of education on voting trends.
- **Sample Size**: The poll is expected to include responses from 10,000 individuals. Assuming nonresponse bias is 10%, we estimate the final adjusted sample size of approximately 9,000.
- **Geographical Distribution**: The survey will be conducted across all 50 states and the District of Columbia. Considering that traditional "red" and "blue" states are less likely to change political alignments, an increased focus will be placed on polling within swing states. 

### Recruitment Plan
This survey will conduct recruiting in following methods:

- **Online recruitment**: Advertisements and official information about the survey will be disseminated through various search engines (including Google and Firefox) and social media platforms such as X and Instagram. All advertisements will contain direct links to the Google Forms survey.  
- **Phone recruitment**: Valid phone numbers will be contacted by staff to conduct the survey using the same set of questions as the online survey. For privacy and security, no conversations will be recorded, and the calling system will automatically dial numbers without disclosing them to staff members.
- **In person recruitment**: A tent will be set up in key high-traffic regions in swing states to conduct survey in-person.
- **Gift incentive**: To increase participation, all respondents will receive a specially designed pin, estimated to cost around $2 each. This incentive is intended to boost engagement and encourage broader participation in the survey.

### Budgect Allocation

- **Online Recruitment Cost**:   $20,000 allocated for advertising across various platforms (search engines and social media).
- **Phone Recruitment Cost**: $20,000 allocated for hiring staff to conduct phone surveys and cover the associated data usage charges.
- **In-Person Recruitment Cost**: $22,000 allocated for hiring field staff and setting up in-person recruitment locations.
- **Gift Cost**: $20,000 allocated for the total value of participant gifts
- **Data Analysis and Quality Control Cost**: $6,000 allocated for employing technical staff, purchasing software licenses, and utilizing required tools.
- **Administrative Cost**: $2,000 allocated for overall management, including miscellaneous expenses and logistical support.

Total Budget: $100,000

### Survey Design
This survey will only collect data that are accurate and unbigoted. Meanwhile, personal information will not be contained.

- **Close-ended Question**: Usage of multiple choice can make sure the answer is straightforward and easier for analysis.
- **Response Option**: Most questions will only contain option from A, B and “prefer not to say”, all the option will be a neutral response.
- **Insensitive Information**: This survey will only contain personal information only and merely age, gender, race, education background, income, living state.

### Data Process
To ensure data we collected are valid and significant, we will conduct following methods to test our data.

- **One-times Submission**: For online surveys, only one submission will be allowed per unique IP address to prevent multiple entries that could skew results. The same principle will apply to phone recruitment, ensuring each number is only surveyed once.
- **Missing Data**: During the data cleaning process, responses with missing values (N/A entries) will be excluded to maintain the integrity and reliability of the analysis.
- **Swing States Data Process**: Data collected from swing states will be assigned a slightly higher weight in the estimation process, given their critical influence on election outcomes.
- **Stratified Analysis**: To gain insights into voter preferences within different demographic subgroups, stratified analyses will be conducted, focusing both on overall trends and trends within specific subgroups.
- **Poll Aggregation Approach**: The aggregated data will be weighted based on sample size (with larger samples receiving greater weight), and past reputable polls will be incorporated, giving priority to highly rated pollsters to strengthen the overall analysis.

### Sample Survey
Google Forms will be used to collect data efficiently and securely, ensuring no information is leaked. The survey will cover aspects such as gender, race, demographics, education, first-choice candidate, and views on the current United States.

A complete sample survey could be found in the following link https://forms.gle/1jrQP7bPqntJ9N2s9 or by clicking [Sample survey ](https://docs.google.com/forms/d/e/1FAIpQLSd_yZTdfVJpPJY0ItPLdJ1xwtL0zQiGmBf8KE_lCJfoy2lJCQ/viewform?usp=sf_link).

Proposed Survey Questions:

1. What sex were you assigned at birth, or on your original birth certificate?
- Male
- Female

2. How do you currently describe your gender?
- Male
- Female
- Transgender
- Non-binary
- other

3. What is your racial self-identification?
- White
- Black
- Asian
- Indigenous
- Prefer not to say
- Other

4. What is your current age?
- Under 18
- 30-45
- 46-51
- 52-66
- over 66

5. What is your highest level of education?
- High school or Under
- Undergraduate
- Graduate
_ Doctor

6. Which  candidate would you vote for in U.S. 2024 Presidential Election?
- Donald Trump (Republic)
- Kamala Harris (Democrat)
- Other

7. Would you vote for the 2024 U.S. Presidential Election?
- Yes
- No
- I'm not sure

8. Are you satisfied with the current situation in the United States?
- Pretty much
- Somewhat satisfied
- Neutral
- Somewhat dissatisfied
- Very Dissatisfied
- No opinion

9. What is your most concerned toward to current U.S?
- Economy
- Employment
- Education
- Environment
- Diplomacy
- Immigration
- Domestic safety


### Conclusion
The processes outlined in this survey aim to provide valid and meaningful insights into the upcoming U.S. 2024 Presidential Election. Working within a limited budget, we have carefully designed the survey and data processing methods to achieve reliable and comprehensive analyses, both at the subgroup level and in the overall population. 

# Model details {#sec-model-details}
## Model Summmary
We print the Model Summaries here for reference.

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: fig-dem_sum
summary_table <- summary(spline_model)
summary_table_rounded <- summary_table
summary_table_rounded[] <- lapply(summary_table_rounded, function(x) if(is.numeric(x)) round(x, 3) else x)

# Display the table with kable
kable(summary_table_rounded, format = "markdown", caption = "Summary Table For Bayesian Spline fit of Democrat Voter Support")
```

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: fig-rep_sum
summary_table <- summary(rep_spline_model)
summary_table_rounded <- summary_table
summary_table_rounded[] <- lapply(summary_table_rounded, function(x) if(is.numeric(x)) round(x, 3) else x)

# Display the table with kable
kable(summary_table_rounded, format = "markdown", caption = "Summary Table For Bayesian Spline fit of Republican Voter Support")
```



\newpage


# References


